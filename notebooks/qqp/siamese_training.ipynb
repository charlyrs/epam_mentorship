{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "any3ew7wALru"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_KGqL9I5qDI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_YwsV-iAhHZ"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade transformers datasets accelerate deepspeed \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import gensim.downloader\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nkG08PwINQt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCAel1BZ5vnl"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nTbG8gj75-Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vy6My0wEAEV"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-d0sTneAyUU"
      },
      "outputs": [],
      "source": [
        "train = datasets.load_dataset('csv', data_files='/content/drive/MyDrive/data/qqp/train.csv')['train']\n",
        "test = datasets.load_dataset('csv', data_files='/content/drive/MyDrive/data/qqp/test.csv')['train']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "aSzJMxHirmsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def token_counter(train, tokenizer):\n",
        "    token_counts = Counter()\n",
        "    for pair in train:\n",
        "        if pair['question1']:\n",
        "          token_counts.update(tokenizer.tokenize(pair['question1']))\n",
        "        else:\n",
        "          token_counts.update(tokenizer.tokenize('Not a question'))\n",
        "        if pair['question2']:\n",
        "          token_counts.update(tokenizer.tokenize(pair['question2']))\n",
        "        else:\n",
        "          token_counts.update(tokenizer.tokenize('Not a question'))\n",
        "    return token_counts\n",
        "\n",
        "\n",
        "def get_tokens(token_counts, min_c, max_c):\n",
        "    return sorted(t for t, c in token_counts.items() if c >= min_c and c <= max_c)\n",
        "\n",
        "\n",
        "def get_embeddings(tokens, name, emb_size, PAD = '<pad>', UNK = '<unk>'):\n",
        "    embeddings = gensim.downloader.load(name)\n",
        "    vocab_npa = np.array(tokens)\n",
        "    embs_npa = np.array([embeddings.get_vector(x) if x in list(embeddings.index_to_key) else np.zeros(emb_size) for x in tokens])\n",
        "\n",
        "    vocab_npa = np.insert(vocab_npa, 0, PAD)\n",
        "    vocab_npa = np.insert(vocab_npa, 1, UNK)\n",
        "    pad_emb_npa = np.zeros((1,embs_npa.shape[1]))   \n",
        "    unk_emb_npa = np.mean(embs_npa,axis=0,keepdims=True) \n",
        "    embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n",
        "    return embs_npa, vocab_npa"
      ],
      "metadata": {
        "id": "BTC8nIbY7b55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40\n",
        "def tokenize_nltk(qqp, tokenizer):\n",
        "    def preprocess_function(examples):\n",
        "        result = {}\n",
        "        result['q1'] = [token_to_id.get(x,1) for x in tokenizer.tokenize(\n",
        "            examples['question1'] if examples['question1'] is not None else 'Not a question', \n",
        "        )]\n",
        "        result['q1'] = result['q1'][:MAX_LENGTH]\n",
        "        result['q1'] = result['q1'] + [0] * (MAX_LENGTH - len(result['q1']))\n",
        "        result['q2'] = [token_to_id.get(x,1) for x in tokenizer.tokenize(\n",
        "            examples['question2'] if examples['question2'] is not None else 'Not a question', \n",
        "        )]\n",
        "        result['q2'] = result['q2'][:MAX_LENGTH]\n",
        "        result['q2'] = result['q2'] + [0] * (MAX_LENGTH - len(result['q2']))\n",
        "        result['label'] = examples['is_duplicate']\n",
        "        return result\n",
        "\n",
        "    qqp_preprocessed = qqp.map(preprocess_function)\n",
        "    return qqp_preprocessed"
      ],
      "metadata": {
        "id": "M4dc6Q0n7Ss8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, calculate_loss, calculate_val_loss, scheduler=None, *args):\n",
        "    train_history = []\n",
        "    dev_history = []\n",
        "    count = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"epoch: {epoch}\")\n",
        "        model.train()\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "                  train_preprocessed, \n",
        "                  batch_size=512, \n",
        "                  shuffle=True, \n",
        "                  collate_fn=transformers.default_data_collator, \n",
        "                  num_workers=2) \n",
        "        for i, batch in enumerate(tqdm(train_loader)):\n",
        "            count += 1\n",
        "            pred = model(batch, *args)\n",
        "            loss = calculate_loss(criterion, pred, batch['labels'])\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_history.append((count, loss.item()))\n",
        "            if (count + 1) % 100 == 0:\n",
        "                clear_output(True)\n",
        "                plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
        "                if len(dev_history):\n",
        "                    plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
        "                plt.legend(); plt.grid(); plt.show()\n",
        "            if (count + 1) % 300 == 0:\n",
        "                print(\"Scoring dev...\")\n",
        "                val_loader = torch.utils.data.DataLoader(\n",
        "                            val_preprocessed, \n",
        "                            batch_size=32, \n",
        "                            shuffle=False, \n",
        "                            collate_fn=transformers.default_data_collator, \n",
        "                            num_workers=2\n",
        "                        ) \n",
        "                dev_history.append((count, calculate_val_loss(model, val_loader, criterion)))\n",
        "                print('#%i Dev loss: %.3f' % dev_history[-1])\n",
        "                \n",
        "        scheduler.step() \n",
        "    return dev_history[-1]"
      ],
      "metadata": {
        "id": "G-2eS0Fh74ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# embeddings model"
      ],
      "metadata": {
        "id": "dKLoq9DL5jjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.train_test_split(test_size = 0.1)"
      ],
      "metadata": {
        "id": "OzSKalqJ7d8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "token_counts = token_counter(train['train'], tokenizer)\n",
        "tokens = get_tokens(token_counts, 50, 10000)"
      ],
      "metadata": {
        "id": "VIAibWAb7hVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs_npa, vocab_npa = get_embeddings(tokens, name='glove-wiki-gigaword-300', emb_size=300)\n",
        "token_to_id = {val: idx for idx, val in enumerate(vocab_npa)}"
      ],
      "metadata": {
        "id": "Bqsnf8xS7AjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preprocessed = tokenize_nltk(train['train'], tokenizer)\n",
        "val_preprocessed = tokenize_nltk(train['test'], tokenizer)"
      ],
      "metadata": {
        "id": "XDdtAeAy7W1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingModel(nn.Module):\n",
        "    def __init__(self, n_tokens=len(tokens), \n",
        "                 emb_len=300):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float()).requires_grad_(True)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        q1 = batch['q1'].to(device)\n",
        "        q2 = batch['q2'].to(device)\n",
        "\n",
        "        q1 = torch.mean(self.emb(q1), dim=1)\n",
        "        q2 = torch.mean(self.emb(q2), dim=1)\n",
        "        \n",
        "        return nn.functional.cosine_similarity(q1, q2)"
      ],
      "metadata": {
        "id": "t_YTYCD45nDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_val_loss_emb_model(model, val_loader, criterion, device=device):\n",
        "    loss_list = []\n",
        "    for _, batch in enumerate(tqdm(val_loader)):\n",
        "        with torch.no_grad():\n",
        "            predicted = model(batch)\n",
        "            batch_loss = criterion(predicted, batch['labels'].to(device).float())\n",
        "            loss_list.append(batch_loss.item())\n",
        "    loss = np.mean(loss_list)\n",
        "    return loss\n",
        "\n",
        "    \n",
        "def calculate_loss_emb_model(criterion, pred, y_true):\n",
        "    return criterion(pred, y_true.to(device).float())\n"
      ],
      "metadata": {
        "id": "VwrfdYi18xtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "                            val_preprocessed, \n",
        "                            batch_size=32, \n",
        "                            shuffle=False, \n",
        "                            collate_fn=transformers.default_data_collator, \n",
        "                            num_workers=2\n",
        "                        ) \n",
        "calculate_val_loss_emb_model(EmbeddingModel().to(device), val_loader, criterion)"
      ],
      "metadata": {
        "id": "s6oItQBf_4W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "model = EmbeddingModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=8e-5, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "train_model(model,\n",
        "            criterion, \n",
        "            optimizer,\n",
        "            calculate_loss_emb_model,\n",
        "            calculate_val_loss_emb_model, \n",
        "            scheduler)"
      ],
      "metadata": {
        "id": "U_6eO1KwAvyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Siamese LSTM"
      ],
      "metadata": {
        "id": "GgMt8Z4kblTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.train_test_split(test_size = 0.1)"
      ],
      "metadata": {
        "id": "YX7WXlMM0qTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "token_counts = token_counter(train['train'], tokenizer)\n",
        "tokens = get_tokens(token_counts, 50, 10000)"
      ],
      "metadata": {
        "id": "IqxQK0fI1iCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs_npa, vocab_npa = get_embeddings(tokens, name='glove-wiki-gigaword-300', emb_size=300)\n",
        "token_to_id = {val: idx for idx, val in enumerate(vocab_npa)}"
      ],
      "metadata": {
        "id": "bHoIXqDR3NIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, delta=0):\n",
        "        super().__init__()\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, x, ans):\n",
        "        q1, q2 = x\n",
        "        ans = ans.squeeze()\n",
        "        dist = torch.norm(q1 - q2, dim=1)\n",
        "        loss = torch.pow(dist[ans == 1].sum() / 2.0, 2)\n",
        "        temp = torch.max(torch.tensor([torch.tensor(0.0), torch.pow((self.delta - dist[ans == 0].sum())/ 2.0, 2)]))\n",
        "        loss += temp\n",
        "        return loss"
      ],
      "metadata": {
        "id": "mwu8-QTN44qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AbsoluteDistance(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, q1, q2):\n",
        "        return torch.abs(q1-q2)\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, q1, q2):\n",
        "        return q1, q2\n",
        "\n",
        "class Concat(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, q1, q2):\n",
        "        return torch.cat((q1,q2), dim=1)\n",
        "\n",
        "\n",
        "class SiameseLSTM(nn.Module):\n",
        "    def __init__(self, n_tokens=len(tokens), \n",
        "                 emb_len=300, \n",
        "                 rec = 80, \n",
        "                 num_layers = 1,\n",
        "                 func = AbsoluteDistance,\n",
        "                 fc = True,\n",
        "                 cat= False):\n",
        "        super().__init__()\n",
        "        self.rec = rec\n",
        "        self.num_layers = num_layers\n",
        "        self.emb = nn.Embedding.from_pretrained(\n",
        "            torch.from_numpy(embs_npa).float()).requires_grad_(True)\n",
        "        self.lstm = nn.LSTM(input_size=emb_len, \n",
        "                            hidden_size=rec, \n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True)\n",
        "        self.bn1 = nn.BatchNorm1d(rec + cat*rec)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.fc1 = nn.Linear(rec + cat*rec, 32)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.func = func()\n",
        "        self.fc_flag = fc\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        q1 = batch['q1'].to(device)\n",
        "        q2 = batch['q2'].to(device)\n",
        "\n",
        "        q1 = self.emb(q1)\n",
        "        hidden, carry = (torch.randn(self.num_layers, len(q1), self.rec), \n",
        "                        torch.randn(self.num_layers, len(q1), self.rec))\n",
        "        hidden, carry =  hidden.to(device), carry.to(device)\n",
        "        q1, _ = self.lstm(q1, (hidden, carry))\n",
        "        \n",
        "        q2 = self.emb(q2)\n",
        "        hidden1, carry1 = (torch.randn(self.num_layers, len(q2), self.rec),\n",
        "                           torch.randn(self.num_layers, len(q2), self.rec))\n",
        "        hidden1, carry1 =  hidden1.to(device), carry1.to(device)\n",
        "        q2, _ = self.lstm(q2, (hidden1, carry1))\n",
        "        \n",
        "        x = self.func(q1[:,-1], q2[:,-1])\n",
        "        if self.fc_flag:\n",
        "            return self.fc2(self.bn2(self.relu(self.fc1(self.bn1(x)))))\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "V0jzZqIXbp3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preprocessed = tokenize_nltk(train['train'], tokenizer)\n",
        "val_preprocessed = tokenize_nltk(train['test'], tokenizer)"
      ],
      "metadata": {
        "id": "GE-M2T1so1My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_val_loss(model, val_loader, criterion, device=device):\n",
        "    loss_list = []\n",
        "    for _, batch in enumerate(tqdm(val_loader)):\n",
        "        with torch.no_grad():\n",
        "            predicted = model(batch)\n",
        "            batch_loss = criterion(predicted, batch['labels'].to(device).float().unsqueeze(1))\n",
        "            loss_list.append(batch_loss.item())\n",
        "    loss = np.mean(loss_list)\n",
        "    return loss\n",
        "\n",
        "def calculate_loss(criterion, pred, y_true):\n",
        "  return criterion(pred, y_true.to(device).float().unsqueeze(1))"
      ],
      "metadata": {
        "id": "GHLXoahfroGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "                            val_preprocessed, \n",
        "                            batch_size=32, \n",
        "                            shuffle=False, \n",
        "                            collate_fn=transformers.default_data_collator, \n",
        "                            num_workers=2\n",
        "                        ) \n",
        "calculate_val_loss(SiameseLSTM().to(device), val_loader, criterion, device=device)"
      ],
      "metadata": {
        "id": "VoiiL39dzyJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20 \n",
        "siamese_model = SiameseLSTM(func = Concat,\n",
        "                 fc = True,\n",
        "                 cat= True).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(siamese_model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "train_model(siamese_model,\n",
        "            criterion, \n",
        "            optimizer,\n",
        "            calculate_loss,\n",
        "            calculate_val_loss, \n",
        "            scheduler)"
      ],
      "metadata": {
        "id": "H8AEIDTFhi-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "                            val_preprocessed, \n",
        "                            batch_size=32, \n",
        "                            shuffle=False, \n",
        "                            collate_fn=transformers.default_data_collator, \n",
        "                            num_workers=2\n",
        "                        ) \n",
        "calculate_val_loss(siamese_model, val_loader, nn.BCEWithLogitsLoss(), device=device)"
      ],
      "metadata": {
        "id": "vi4tEXspK-hU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "any3ew7wALru",
        "QCAel1BZ5vnl",
        "dKLoq9DL5jjl",
        "XssHirYH-tIK"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}